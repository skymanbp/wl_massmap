{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630e549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[peaks] detected 2 cluster(s).\n",
      "[OK] saved -> C:\\Users\\skyma\\Desktop\\t1\\shear_out\\sep4000px_w_shear.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Inverse Shear Calculator — auto-detect cluster count from peaks.csv\n",
    "# 支持 NFW 或 SIS；当 peaks.csv 为空/缺失时，自动按“无 cluster”处理（g=0）\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# -------------------------\n",
    "# 0) 配置区（按需修改）\n",
    "# -------------------------\n",
    "class CFG:\n",
    "    # ---- 工作/路径 ----\n",
    "    # ---- 工作/路径 ----\n",
    "    BASE_DIR = Path(\"C:/Users/skyma/Desktop/t1\")\n",
    "    OUT_DIR  = BASE_DIR / \"shear_out\"\n",
    "    INPUT_CSV  = BASE_DIR / \"csv/sep4000px.csv\"     # 观测(透镜后) catalog\n",
    "    OUTPUT_CSV = OUT_DIR  / \"sep4000px_w_shear.csv\"   # 反剪切输出\n",
    "    PEAKS_CSV  = BASE_DIR / \"batch_sep/sep4000px_peaks.csv\"  # cluster 峰值位置文件（允许无此文件）\n",
    "\n",
    "    # ---- 成像/数值参数 ----\n",
    "    PIXSCALE_ARCSEC = 0.263\n",
    "    R_MIN_ARCSEC    = 1e-3        # 小半径数值保护\n",
    "    G_MAX           = 0.95        # |g| 上限（稳定）\n",
    "\n",
    "    # ---- 质量模型选择 ----\n",
    "    MASS_MODEL = \"SIS\"            # \"NFW\" 或 \"SIS\"\n",
    "\n",
    "    # ---- NFW 参数 ----\n",
    "    M200C_MSUN = 8e14\n",
    "    C200       = 4.0\n",
    "    Z_LENS     = 0.3\n",
    "    Z_SOURCE   = 1.0\n",
    "    H0         = 70.0\n",
    "    OMEGA_M    = 0.3\n",
    "    OMEGA_L    = 1.0 - OMEGA_M\n",
    "\n",
    "    # ---- SIS 参数 ----\n",
    "    THETA_E_ARCSEC = 30.0\n",
    "    CORE_ARCSEC    = 2.0\n",
    "\n",
    "    # ---- 椭率约定与输出 ----\n",
    "    ELLIP_CONVENTION  = \"epsilon\"    # 'epsilon' 或 'chi'\n",
    "    WRITE_TO_NEW_COLS = True         # True: 写 e1_intrinsic/e2_intrinsic；False: 覆盖 e1/e2\n",
    "    E_MAX_AFTER       = 0.95         # 反剪切后裁剪 |e| 上限；None 关闭\n",
    "    ADD_GT_GX         = True         # 仅当 >=1 个 cluster 时才写 g_t/g_x\n",
    "\n",
    "# -------------------------\n",
    "# 1) 椭率/剪切 变换 & 逆变换\n",
    "# -------------------------\n",
    "def e12_to_complex(e1, e2): return e1 + 1j*e2\n",
    "def complex_to_e12(z): return np.real(z), np.imag(z)\n",
    "\n",
    "def epsilon_to_chi(eps):\n",
    "    mod2 = np.abs(eps)**2\n",
    "    return (2*eps) / (1 + mod2 + 1e-12)\n",
    "\n",
    "def chi_to_epsilon(chi):\n",
    "    mod = np.abs(chi)\n",
    "    denom = 1 + np.sqrt(np.maximum(1 - mod**2, 0.0))\n",
    "    denom = np.where(denom == 0, 1e-12, denom)\n",
    "    return chi / denom\n",
    "\n",
    "def lens_inverse_epsilon(e1_obs, e2_obs, g1, g2):\n",
    "    eps_o = e12_to_complex(e1_obs, e2_obs)\n",
    "    g     = e12_to_complex(g1, g2)\n",
    "    den = 1 - np.conjugate(g)*eps_o\n",
    "    den = np.where(np.abs(den)==0, 1e-12+0j, den)\n",
    "    eps_s = (eps_o - g) / den\n",
    "    return complex_to_e12(eps_s)\n",
    "\n",
    "def lens_inverse_chi(e1_obs, e2_obs, g1, g2):\n",
    "    chi_o = e12_to_complex(e1_obs, e2_obs)\n",
    "    eps_o = chi_to_epsilon(chi_o)\n",
    "    e1s, e2s = lens_inverse_epsilon(np.real(eps_o), np.imag(eps_o), g1, g2)\n",
    "    chi_s = epsilon_to_chi(e1s + 1j*e2s)\n",
    "    return complex_to_e12(chi_s)\n",
    "\n",
    "def tangential_cross(g1, g2, dx, dy):\n",
    "    phi = np.arctan2(dy, dx)\n",
    "    c2, s2 = np.cos(2*phi), np.sin(2*phi)\n",
    "    g_t = -(g1*c2 + g2*s2)\n",
    "    g_x =  (g1*s2 - g2*c2)\n",
    "    return g_t, g_x\n",
    "\n",
    "# -------------------------\n",
    "# 2) 读 peaks.csv（允许 0 个 cluster）\n",
    "# -------------------------\n",
    "def load_peaks_csv_allow_empty(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    读取 peaks.csv（至少包含 x_peak,y_peak 列）。\n",
    "    - 文件不存在 / 为空 / 列缺失：返回空 DataFrame（0 个 cluster）\n",
    "    - 正常：返回 DataFrame，附加 cluster_id（1..N）\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (path is None) or (not Path(path).exists()):\n",
    "            return pd.DataFrame(columns=[\"cluster_id\",\"x_peak\",\"y_peak\"])\n",
    "        peaks = pd.read_csv(path)\n",
    "        if not {\"x_peak\",\"y_peak\"}.issubset(peaks.columns):\n",
    "            return pd.DataFrame(columns=[\"cluster_id\",\"x_peak\",\"y_peak\"])\n",
    "        peaks = peaks[[\"x_peak\",\"y_peak\"]].copy()\n",
    "        peaks = peaks.dropna()\n",
    "        if len(peaks)==0:\n",
    "            return pd.DataFrame(columns=[\"cluster_id\",\"x_peak\",\"y_peak\"])\n",
    "        peaks.insert(0, \"cluster_id\", np.arange(1, len(peaks)+1, dtype=int))\n",
    "        return peaks\n",
    "    except Exception:\n",
    "        # 任何读入异常 → 视作无 peaks\n",
    "        return pd.DataFrame(columns=[\"cluster_id\",\"x_peak\",\"y_peak\"])\n",
    "\n",
    "# -------------------------\n",
    "# 3) 宇宙学与 NFW 解析\n",
    "# -------------------------\n",
    "C_LIGHT = 299792.458               # km/s\n",
    "G_MPC   = 4.30091e-9               # (Mpc km^2 / s^2) / Msun\n",
    "\n",
    "def Ez(z, Om, Ol): return np.sqrt(Om*(1+z)**3 + Ol)\n",
    "\n",
    "def comoving_distance_Mpc(z, H0, Om, Ol, n=2048):\n",
    "    if z <= 0: return 0.0\n",
    "    zs = np.linspace(0.0, float(z), n+1)\n",
    "    integrand = 1.0 / Ez(zs, Om, Ol)\n",
    "    dz = float(z) / n\n",
    "    S = integrand[0] + integrand[-1] + 4*integrand[1:-1:2].sum() + 2*integrand[2:-2:2].sum()\n",
    "    return (C_LIGHT / H0) * (dz/3.0) * S\n",
    "\n",
    "def angular_diameter_distance_Mpc(z1, z2, H0, Om, Ol):\n",
    "    if z2 <= z1: return 0.0\n",
    "    chi2 = comoving_distance_Mpc(z2, H0, Om, Ol)\n",
    "    chi1 = comoving_distance_Mpc(z1, H0, Om, Ol)\n",
    "    return (chi2 - chi1) / (1 + z2)\n",
    "\n",
    "def sigma_crit_Msun_per_Mpc2(zl, zs, H0, Om, Ol):\n",
    "    Dd = angular_diameter_distance_Mpc(0.0, zl, H0, Om, Ol)\n",
    "    Ds = angular_diameter_distance_Mpc(0.0, zs, H0, Om, Ol)\n",
    "    Dds= angular_diameter_distance_Mpc(zl, zs, H0, Om, Ol)\n",
    "    if Dd<=0 or Ds<=0 or Dds<=0: return np.inf\n",
    "    return (C_LIGHT**2 / (4*np.pi*G_MPC)) * (Ds / (Dd * Dds))\n",
    "\n",
    "def rho_c_crit_Msun_per_Mpc3(z, H0, Om, Ol):\n",
    "    Hz = H0 * Ez(z, Om, Ol)\n",
    "    return 3*(Hz**2) / (8*np.pi*G_MPC)\n",
    "\n",
    "def nfw_scale_params(M200c, c200, z, H0, Om, Ol):\n",
    "    rho_c = rho_c_crit_Msun_per_Mpc3(z, H0, Om, Ol)\n",
    "    r200c = (3*M200c/(4*np.pi*200*rho_c))**(1/3)     # Mpc\n",
    "    rs = r200c / c200\n",
    "    delta_c = (200.0/3.0) * (c200**3) / (np.log(1+c200) - c200/(1+c200))\n",
    "    rho_s = delta_c * rho_c\n",
    "    return r200c, rs, rho_s\n",
    "\n",
    "def _F_kappa(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    out = np.zeros_like(x)\n",
    "    xm1 = x - 1.0\n",
    "    mask_lt = x < (1 - 1e-6)\n",
    "    mask_eq = np.abs(xm1) <= 1e-6\n",
    "    mask_gt = x > (1 + 1e-6)\n",
    "    if np.any(mask_lt):\n",
    "        xx = x[mask_lt]\n",
    "        sq = np.sqrt(1.0 - xx**2)\n",
    "        at = np.arctanh(np.clip(np.sqrt((1-xx)/(1+xx)), 0, 1-1e-12))\n",
    "        out[mask_lt] = (1 - 2*at/sq) / (xx**2 - 1)\n",
    "    out[mask_eq] = 1.0/3.0\n",
    "    if np.any(mask_gt):\n",
    "        xx = x[mask_gt]\n",
    "        sq = np.sqrt(xx**2 - 1.0)\n",
    "        at = np.arctan(np.sqrt((xx-1)/(1+xx)))\n",
    "        out[mask_gt] = (1 - 2*at/sq) / (xx**2 - 1)\n",
    "    return out\n",
    "\n",
    "def _G_bar(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    out = np.zeros_like(x)\n",
    "    xm1 = x - 1.0\n",
    "    mask_lt = x < (1 - 1e-6)\n",
    "    mask_eq = np.abs(xm1) <= 1e-6\n",
    "    mask_gt = x > (1 + 1e-6)\n",
    "    if np.any(mask_lt):\n",
    "        xx = x[mask_lt]\n",
    "        term = np.arctanh(np.clip(np.sqrt((1-xx)/(1+xx)), 0, 1-1e-12))\n",
    "        out[mask_lt] = np.log(xx/2.0) + 2*term/np.sqrt(1-xx**2)\n",
    "    out[mask_eq] = 1 + np.log(0.5)\n",
    "    if np.any(mask_gt):\n",
    "        xx = x[mask_gt]\n",
    "        term = np.arctan(np.sqrt((xx-1)/(1+xx)))\n",
    "        out[mask_gt] = np.log(xx/2.0) + 2*term/np.sqrt(xx**2 - 1)\n",
    "    return out\n",
    "\n",
    "def nfw_kappa_gamma_t(R_phys_Mpc, rs_Mpc, kappa_s):\n",
    "    x = np.maximum(R_phys_Mpc/rs_Mpc, 1e-12)\n",
    "    f = _F_kappa(x)\n",
    "    G = _G_bar(x)\n",
    "    kappa = 2.0 * kappa_s * f\n",
    "    kappa_bar = 4.0 * kappa_s * G / (x**2)\n",
    "    gamma_t = kappa_bar - kappa\n",
    "    return kappa, gamma_t\n",
    "\n",
    "# -------------------------\n",
    "# 4) 剪切场：NFW（严谨叠加） & SIS（严谨）\n",
    "# -------------------------\n",
    "def shear_field_NFW_rigorous(xs, ys, peaks_xy, cfg: CFG):\n",
    "    xs = np.asarray(xs); ys = np.asarray(ys)\n",
    "    # 预计算 NFW 尺度参数\n",
    "    sigcrit = sigma_crit_Msun_per_Mpc2(cfg.Z_LENS, cfg.Z_SOURCE, cfg.H0, cfg.OMEGA_M, cfg.OMEGA_L)\n",
    "    r200c, rs, rho_s = nfw_scale_params(cfg.M200C_MSUN, cfg.C200, cfg.Z_LENS, cfg.H0, cfg.OMEGA_M, cfg.OMEGA_L)\n",
    "    kappa_s = (rho_s * rs) / sigcrit\n",
    "    Dd = angular_diameter_distance_Mpc(0.0, cfg.Z_LENS, cfg.H0, cfg.OMEGA_M, cfg.OMEGA_L)\n",
    "\n",
    "    kappa_tot = np.zeros_like(xs, dtype=float)\n",
    "    gamma_c_tot = np.zeros_like(xs, dtype=complex)\n",
    "\n",
    "    for (x0, y0) in peaks_xy:\n",
    "        dx = xs - x0; dy = ys - y0\n",
    "        R_pix = np.hypot(dx, dy)\n",
    "        R_arcsec = np.sqrt((R_pix*cfg.PIXSCALE_ARCSEC)**2 + cfg.R_MIN_ARCSEC**2)\n",
    "        theta_rad = R_arcsec * (np.pi / (180.0*3600.0))\n",
    "        R_phys = Dd * theta_rad\n",
    "        kappa_i, gamma_t_i = nfw_kappa_gamma_t(R_phys, rs, kappa_s)\n",
    "\n",
    "        phi = np.arctan2(dy, dx)\n",
    "        gamma_c_tot += - gamma_t_i * np.exp(2j*phi)  # 自旋-2切向\n",
    "        kappa_tot   +=   kappa_i\n",
    "\n",
    "    denom = np.maximum(1 - kappa_tot, 1e-6)\n",
    "    g_c = gamma_c_tot / denom\n",
    "    mod = np.abs(g_c)\n",
    "    m = mod > cfg.G_MAX\n",
    "    if np.any(m): g_c[m] *= (cfg.G_MAX / mod[m])\n",
    "    return np.real(g_c), np.imag(g_c)\n",
    "\n",
    "def shear_field_SIS_rigorous(xs, ys, peaks_xy, cfg: CFG):\n",
    "    xs = np.asarray(xs); ys = np.asarray(ys)\n",
    "    g1 = np.zeros_like(xs); g2 = np.zeros_like(ys)\n",
    "    for (x0, y0) in peaks_xy:\n",
    "        dx = xs - x0; dy = ys - y0\n",
    "        R_pix = np.hypot(dx, dy)\n",
    "        R_arc = np.sqrt((R_pix*cfg.PIXSCALE_ARCSEC)**2 + cfg.CORE_ARCSEC**2)\n",
    "        kappa = 0.5 * cfg.THETA_E_ARCSEC / np.maximum(R_arc, 1e-9)\n",
    "        gamma = kappa\n",
    "        g_mod = gamma / np.maximum(1 - kappa, 1e-6)\n",
    "        g_mod = np.clip(g_mod, 0.0, cfg.G_MAX)\n",
    "        phi = np.arctan2(dy, dx)\n",
    "        g1 += - g_mod * np.cos(2*phi)\n",
    "        g2 += - g_mod * np.sin(2*phi)\n",
    "    return g1, g2\n",
    "\n",
    "# -------------------------\n",
    "# 5) 反剪切写回 DataFrame\n",
    "# -------------------------\n",
    "def apply_inverse_reduced_shear_to_df(df, g1, g2, e1_col=\"e1\", e2_col=\"e2\",\n",
    "                                      convention=\"epsilon\", write_to_new_cols=True, suffix=\"_intrinsic\", e_max=None):\n",
    "    e1o = df[e1_col].to_numpy(); e2o = df[e2_col].to_numpy()\n",
    "    if convention == \"epsilon\":\n",
    "        e1s, e2s = lens_inverse_epsilon(e1o, e2o, g1, g2)\n",
    "    elif convention == \"chi\":\n",
    "        e1s, e2s = lens_inverse_chi(e1o, e2o, g1, g2)\n",
    "    else:\n",
    "        raise ValueError(\"convention must be 'epsilon' or 'chi'\")\n",
    "\n",
    "    if e_max is not None:\n",
    "        e_mod = np.sqrt(e1s**2 + e2s**2)\n",
    "        m = e_mod > e_max\n",
    "        if np.any(m):\n",
    "            scale = e_max / (e_mod[m] + 1e-12)\n",
    "            e1s[m] *= scale; e2s[m] *= scale\n",
    "\n",
    "    if write_to_new_cols:\n",
    "        df[e1_col + suffix] = e1s\n",
    "        df[e2_col + suffix] = e2s\n",
    "    else:\n",
    "        df[e1_col] = e1s\n",
    "        df[e2_col] = e2s\n",
    "    return df\n",
    "\n",
    "# -------------------------\n",
    "# 6) 主流程\n",
    "# -------------------------\n",
    "def main(cfg: CFG):\n",
    "    Path(cfg.OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(cfg.INPUT_CSV)\n",
    "    need = {\"x\",\"y\",\"e1\",\"e2\"}\n",
    "    if not need.issubset(df.columns):\n",
    "        raise ValueError(f\"{cfg.INPUT_CSV} 缺少必要列: {need}\")\n",
    "\n",
    "    # 自动读取 peaks.csv（允许 0 个）\n",
    "    peaks_df = load_peaks_csv_allow_empty(cfg.PEAKS_CSV)\n",
    "    n_peaks = len(peaks_df)\n",
    "    print(f\"[peaks] detected {n_peaks} cluster(s).\")\n",
    "\n",
    "    if n_peaks == 0:\n",
    "        # 无 cluster：g=0，反剪切后即为本征（=观测）\n",
    "        print(\"[info] No clusters found. Using g=0 everywhere.\")\n",
    "        g1 = np.zeros(len(df), dtype=float)\n",
    "        g2 = np.zeros(len(df), dtype=float)\n",
    "    else:\n",
    "        peaks_xy = list(zip(peaks_df[\"x_peak\"].to_numpy(), peaks_df[\"y_peak\"].to_numpy()))\n",
    "        if cfg.MASS_MODEL.upper() == \"NFW\":\n",
    "            g1, g2 = shear_field_NFW_rigorous(\n",
    "                xs=df[\"x\"].to_numpy(), ys=df[\"y\"].to_numpy(),\n",
    "                peaks_xy=peaks_xy, cfg=cfg\n",
    "            )\n",
    "        elif cfg.MASS_MODEL.upper() == \"SIS\":\n",
    "            g1, g2 = shear_field_SIS_rigorous(\n",
    "                xs=df[\"x\"].to_numpy(), ys=df[\"y\"].to_numpy(),\n",
    "                peaks_xy=peaks_xy, cfg=cfg\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"MASS_MODEL 必须为 'NFW' 或 'SIS'\")\n",
    "\n",
    "    # 反剪切\n",
    "    df = apply_inverse_reduced_shear_to_df(\n",
    "        df, g1, g2,\n",
    "        e1_col=\"e1\", e2_col=\"e2\",\n",
    "        convention=cfg.ELLIP_CONVENTION,\n",
    "        write_to_new_cols=cfg.WRITE_TO_NEW_COLS,\n",
    "        suffix=\"_intrinsic\",\n",
    "        e_max=cfg.E_MAX_AFTER\n",
    "    )\n",
    "\n",
    "    # 可选：只有有 cluster 时才计算 g_t/g_x（以第一个峰为中心）\n",
    "    if cfg.ADD_GT_GX and n_peaks > 0:\n",
    "        x0, y0 = peaks_df.loc[0, \"x_peak\"], peaks_df.loc[0, \"y_peak\"]\n",
    "        gt, gx = tangential_cross(g1, g2, df[\"x\"].to_numpy()-x0, df[\"y\"].to_numpy()-y0)\n",
    "        df[\"g_t\"] = gt; df[\"g_x\"] = gx\n",
    "\n",
    "\n",
    "    base, ext = os.path.splitext(cfg.OUTPUT_CSV)\n",
    "    output_path = f\"{base}_{cfg.MASS_MODEL}{ext}\"\n",
    "    df.to_csv(output_path, index=False, float_format=\"%.9f\")\n",
    "    print(f\"[OK] saved -> {cfg.OUTPUT_CSV}\")\n",
    "\n",
    "# 运行\n",
    "if __name__ == \"__main__\":\n",
    "    main(CFG)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
